import streamlit as st
from groq import Groq
import base64
import os
import pandas as pd
import PyPDF2
from dotenv import load_dotenv

# ==========================================
# 1. BRAIN & CONFIG (‡∏™‡∏°‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å)
# ==========================================
load_dotenv()
try:
    API_KEY = st.secrets.get("GROQ_API_KEY") or os.getenv("GROQ_API_KEY")
except:
    API_KEY = os.getenv("GROQ_API_KEY")

# üî• ‡∏ù‡∏±‡∏á‡∏ô‡∏¥‡∏™‡∏±‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏â‡∏•‡∏≤‡∏î + ‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß + ‡∏°‡∏µ‡∏Ñ‡∏≤‡πÅ‡∏£‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå)
SYSTEM_PROMPT = """
Role: ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (Senior Expert & Buddy)
Language: ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥, ‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á, ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ '‡∏Ñ‡∏∞/‡∏Ñ‡πà‡∏∞' ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ '‡∏Ñ‡∏£‡∏±‡∏ö' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á)

Instruction (‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç):
1. **‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (Detailed):** ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏´‡πâ‡∏ß‡∏ô‡πÜ ‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î! ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏õ ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏™‡∏°‡∏≠
2. **‡∏Ñ‡∏¥‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (Chain of Thought):** ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏à‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡πÜ ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÜ (Bullet points) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
3. **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á (Tone):** ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å‡πÜ ‡∏õ‡∏≤‡∏Å‡πÅ‡∏à‡πã‡∏ß‡∏ô‡∏¥‡∏î‡πÜ ‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡πÄ‡∏ö‡∏∑‡πà‡∏≠
4. **‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î (Coding):** ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (Best Practice) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
5. **‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß‡πà‡∏≤ "‡πÇ‡∏´... ‡∏£‡∏π‡πâ‡∏•‡∏∂‡∏Å‡∏à‡∏±‡∏á‡∏ß‡∏∞" ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö
"""

st.set_page_config(page_title="Gemini V15", page_icon="üß†", layout="wide")

# ==========================================
# 2. UI STYLE (‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Thai:wght@300;400;600&display=swap');
    html, body, [class*="css"] { font-family: 'Noto Sans Thai', sans-serif; }
    
    footer {visibility: hidden;} .stDeployButton {display:none;}
    .stApp {background-color: #ffffff;}

    /* Chat Bubble */
    .stChatMessage { background-color: transparent; border: none; }
    div[data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #eff3f8; border-radius: 20px;
        padding: 15px 25px; margin-bottom: 15px; color: #1f1f1f;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05); /* ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏≤‡πÉ‡∏´‡πâ‡∏ô‡∏π‡∏ô‡∏™‡∏ß‡∏¢ */
        line-height: 1.6; /* ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÜ */
    }
    div[data-testid="stChatMessage"]:nth-child(even) {
        background-color: transparent; padding: 0px 10px; margin-bottom: 15px;
        line-height: 1.6;
    }

    /* Floating Button (‡∏Ç‡∏ß‡∏≤‡∏•‡πà‡∏≤‡∏á) */
    .stPopover {
        position: fixed; bottom: 85px; right: 30px; z-index: 999999;
        width: auto !important; height: auto !important; display: inline-block !important;
    }
    .stPopover button {
        background-color: #f0f4f9 !important; color: #444746 !important;
        border: none !important; border-radius: 50% !important;
        width: 55px !important; height: 55px !important; /* ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á */
        font-size: 24px !important; box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .stPopover button:hover {
        background-color: #d3e3fd !important; color: #0b57d0 !important; transform: scale(1.1);
    }

    /* Input Box Adjustment */
    .stChatInputContainer textarea { padding-right: 70px !important; }
    div[data-testid="stChatInput"] { padding-bottom: 20px; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

def extract_file(uploaded_file):
    try:
        if "pdf" in uploaded_file.type:
            pdf = PyPDF2.PdfReader(uploaded_file)
            return "".join([p.extract_text() for p in pdf.pages])
        elif "csv" in uploaded_file.type:
            return pd.read_csv(uploaded_file).to_markdown(index=False)
        elif "excel" in uploaded_file.type:
            return pd.read_excel(uploaded_file).to_markdown(index=False)
        else:
            return uploaded_file.getvalue().decode("utf-8")
    except: return "‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"

def stream_parser(stream):
    for chunk in stream:
        if chunk.choices and chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

# ==========================================
# 4. MAIN APP
# ==========================================
with st.sidebar:
    st.title("üß† Gemini Ultimate")
    st.caption("Version 15: Deep Thinker")
    if st.button("‚ûï Clear Chat", type="primary", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    st.markdown("---")
    st.info("üí° Tip: ‡∏ñ‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏ö‡∏≠‡∏ó‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏£‡∏±‡∏ö")

if "messages" not in st.session_state: st.session_state.messages = []

# Welcome text
if not st.session_state.messages:
    st.markdown("""
    <div style="text-align: center; margin-top: 60px;">
        <h1 style="background: linear-gradient(to right, #0b57d0, #a142f4); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">
            ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏û‡∏µ‡πà! üß†
        </h1>
        <p style="color: gray; font-size: 1.1em;">‡∏ñ‡∏≤‡∏°‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ú‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏ö‡∏ö‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å!</p>
    </div>
    """, unsafe_allow_html=True)

# Render Chat
for msg in st.session_state.messages:
    role = msg["role"]
    avatar = "üë§" if role == "user" else "üß†"
    with st.chat_message(role, avatar=avatar):
        if isinstance(msg["content"], list):
            for p in msg["content"]:
                if p["type"]=="text": st.markdown(p["text"])
                if p["type"]=="image_url": st.image(p["image_url"]["url"], width=250)
        else:
            st.markdown(msg["content"])

# File Uploader
with st.popover("üìé", help="‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå"):
    uploaded_file = st.file_uploader("Upload", label_visibility="collapsed")
    file_txt = extract_file(uploaded_file) if uploaded_file and "image" not in uploaded_file.type else ""

# Input & Logic
if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏°‡∏≤‡πÄ‡∏•‡∏¢..."):
    st.chat_message("user", avatar="üë§").markdown(prompt)
    
    # Logic
    user_content = prompt
    model = "llama-3.3-70b-versatile"
    
    # ‡πÉ‡∏ä‡πâ System Prompt ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ù‡∏±‡∏á‡πÑ‡∏ß‡πâ‡πÄ‡∏•‡∏¢
    final_instruction = SYSTEM_PROMPT

    if uploaded_file:
        if "image" in uploaded_file.type:
            model = "meta-llama/llama-4-scout-17b-16e-instruct"
            img = encode_image(uploaded_file)
            user_content = [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img}"}}]
        else:
            final_instruction += f"\n\n[‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏ö]: {file_txt}\n‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
    
    st.session_state.messages.append({"role": "user", "content": user_content})

    # ‡∏™‡πà‡∏á API
    with st.chat_message("assistant", avatar="üß†"):
        try:
            client = Groq(api_key=API_KEY)
            
            messages = [{"role": "system", "content": final_instruction}]
            # ‡∏¢‡πà‡∏≠ History ‡πÄ‡∏Å‡πà‡∏≤‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Token ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏à‡∏≥‡πÑ‡∏î‡πâ
            for m in st.session_state.messages[:-1]:
                content = m["content"]
                if isinstance(content, list):
                    content = "".join([x["text"] for x in content if x["type"]=="text"])
                messages.append({"role": m["role"], "content": content})
            messages.append({"role": "user", "content": user_content})

            stream = client.chat.completions.create(
                messages=messages, 
                model=model, 
                temperature=0.7,   # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ß‡∏•‡∏á‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏â‡∏•‡∏≤‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
                max_tokens=6000,   # üî• ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏¢‡∏µ‡∏¢‡∏î (‡∏™‡∏∞‡πÉ‡∏à‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô)
                stream=True
            )
            response = st.write_stream(stream_parser(stream))
            st.session_state.messages.append({"role": "assistant", "content": response})

        except Exception as e:
            st.error(f"Error: {e}")