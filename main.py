import streamlit as st
from groq import Groq
import base64
import os
import pandas as pd
import PyPDF2
from dotenv import load_dotenv

# --- 1. SETUP ---
load_dotenv()
try:
    if "GROQ_API_KEY" in st.secrets:
        api_key = st.secrets["GROQ_API_KEY"]
    else:
        api_key = os.getenv("GROQ_API_KEY")
except:
    api_key = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="Gemini Pro Chat", page_icon="‚ú®", layout="wide")

# --- 2. CSS STYLING (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç) ---
st.markdown("""
<style>
    /* ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≤‡∏ß‡∏™‡∏∞‡∏≠‡∏≤‡∏î */
    .stApp {
        background-color: #ffffff;
        color: #1f1f1f;
    }
    
    /* ‡∏ã‡πà‡∏≠‡∏ô Header/Footer ‡∏Ç‡∏≠‡∏á Streamlit */
    header {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* --- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå (Floating Action Button) --- */
    .stPopover {
        position: fixed;
        bottom: 70px; /* ‡∏™‡∏π‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡∏•‡πà‡∏≤‡∏á (‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå) */
        left: 15px;   /* ‡∏ä‡∏¥‡∏î‡∏ã‡πâ‡∏≤‡∏¢ */
        z-index: 1000;
    }
    
    /* ‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡∏•‡∏¥‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏°‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡∏ç‡πà ‡∏Å‡∏î‡∏á‡πà‡∏≤‡∏¢ */
    .stPopover button {
        background-color: #f0f4f9 !important;
        color: #444746 !important;
        border: none !important;
        border-radius: 50% !important;
        width: 55px !important;
        height: 55px !important;
        font-size: 24px !important;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .stPopover button:hover {
        background-color: #d3e3fd !important;
        color: #0b57d0 !important;
        transform: scale(1.1);
    }

    /* --- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Chat Bubble --- */
    .stChatMessage {
        background-color: transparent;
        border: none;
    }
    /* ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° User (‡∏™‡∏µ‡πÄ‡∏ó‡∏≤‡∏à‡∏≤‡∏á‡πÜ ‡∏°‡∏ô‡πÜ) */
    div[data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #f2f2f2; 
        border-radius: 20px;
        padding: 1rem;
        margin-bottom: 10px;
    }
    
    /* ‡∏Ç‡∏¢‡∏±‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡πâ‡∏´‡∏•‡∏ö‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå */
    .stChatInputContainer {
        padding-bottom: 20px;
        padding-left: 60px; /* ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡∏•‡∏¥‡∏õ */
    }
</style>
""", unsafe_allow_html=True)

# --- 3. HELPER FUNCTIONS ---
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

def extract_text_from_file(uploaded_file):
    try:
        if "pdf" in uploaded_file.type:
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            return "".join([page.extract_text() for page in pdf_reader.pages])
        elif "csv" in uploaded_file.type:
            return pd.read_csv(uploaded_file).to_markdown(index=False)
        elif "excel" in uploaded_file.type or "spreadsheet" in uploaded_file.type:
            return pd.read_excel(uploaded_file).to_markdown(index=False)
        else:
            return uploaded_file.getvalue().decode("utf-8")
    except Exception as e:
        return f"Error reading file: {str(e)}"

# --- 4. TOP BAR (‡πÅ‡∏ó‡∏ô Sidebar) ---
col1, col2 = st.columns([8, 1])
with col1:
    st.markdown("### ‚ú® Gemini Chat")
with col2:
    # ‡∏õ‡∏∏‡πà‡∏°‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ (Setting) ‡πÅ‡∏ö‡∏ö Popover ‡∏°‡∏∏‡∏°‡∏Ç‡∏ß‡∏≤‡∏ö‡∏ô
    with st.popover("‚öôÔ∏è", help="‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ö‡∏≠‡∏ó"):
        st.markdown("### ü§ñ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ô‡∏¥‡∏™‡∏±‡∏¢")
        mode = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î", ["Smart (‡∏â‡∏•‡∏≤‡∏î)", "Creative (‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô)", "Coder (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°)"])
        st.markdown("---")
        if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏ä‡∏ó (Reset)", type="primary", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

# --- 5. LOGIC & UI ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á Chat History
for msg in st.session_state.messages:
    if msg["role"] == "user":
        with st.chat_message("user", avatar="üë§"):
            content = msg["content"]
            if isinstance(content, list):
                for part in content:
                    if part["type"] == "text": st.markdown(part["text"])
                    if part["type"] == "image_url": st.image(part["image_url"]["url"], width=250)
            else:
                st.markdown(content)
    else:
        with st.chat_message("assistant", avatar="‚ú®"):
            st.markdown(msg["content"])

# --- ‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå (‡∏•‡∏≠‡∏¢‡∏≠‡∏¢‡∏π‡πà‡∏°‡∏∏‡∏°‡∏ã‡πâ‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏á) ---
with st.popover("üìé", help="‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå"):
    st.markdown("###### üìÇ ‡πÅ‡∏ô‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ / ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
    uploaded_file = st.file_uploader(
        "Upload", 
        type=["pdf", "csv", "xlsx", "txt", "jpg", "png"],
        label_visibility="collapsed"
    )
    
    file_content = ""
    is_image = False
    
    if uploaded_file:
        st.success(f"‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡πà‡∏á: {uploaded_file.name}")
        if "image" in uploaded_file.type:
            is_image = True
            st.image(uploaded_file, width=150)
        else:
            file_content = extract_text_from_file(uploaded_file)

# --- ‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ---
if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..."):
    # 1. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° User
    st.chat_message("user", avatar="üë§").markdown(prompt)
    
    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Context
    user_msg_obj = prompt
    model_to_use = "llama-3.3-70b-versatile"
    
    # System Prompt ‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î
    system_prompts = {
        "Smart (‡∏â‡∏•‡∏≤‡∏î)": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏â‡∏•‡∏≤‡∏î ‡∏ï‡∏≠‡∏ö‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡∏™‡∏∏‡∏†‡∏≤‡∏û",
        "Creative (‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô)": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏π‡πà‡∏Ñ‡∏¥‡∏î ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á",
        "Coder (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°)": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå‡∏°‡∏∑‡∏≠‡πÇ‡∏õ‡∏£ ‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ"
    }
    base_prompt = system_prompts.get(mode, "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢")
    
    if uploaded_file:
        if is_image:
            model_to_use = "meta-llama/llama-4-scout-17b-16e-instruct" # Vision Model
            base64_img = encode_image(uploaded_file)
            user_msg_obj = [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
            ]
            st.session_state.messages.append({"role": "user", "content": user_msg_obj})
        else:
            base_prompt += f"\n\n[‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏ö]:\n{file_content}\n\n[‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á]: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô"
            st.session_state.messages.append({"role": "user", "content": prompt})
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})

    # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡πà‡∏á API
    messages_payload = [{"role": "system", "content": base_prompt}]
    for m in st.session_state.messages[:-1]:
        c = m["content"]
        if isinstance(c, list):
            text_only = ""
            for p in c:
                if p["type"] == "text": text_only += p["text"]
            messages_payload.append({"role": m["role"], "content": text_only})
        else:
            messages_payload.append({"role": m["role"], "content": c})
            
    messages_payload.append({"role": "user", "content": user_msg_obj})

    # 4. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å AI ‡πÅ‡∏•‡∏∞ **‡πÅ‡∏Å‡∏∞‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°** (‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏î‡∏≤‡∏ß)
    with st.chat_message("assistant", avatar="‚ú®"):
        try:
            client = Groq(api_key=api_key)
            stream = client.chat.completions.create(
                messages=messages_payload,
                model=model_to_use,
                temperature=0.7,
                stream=True,
            )
            
            # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡∏∞‡∏Å‡∏•‡πà‡∏≠‡∏á (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!) ---
            def parse_stream(stream):
                for chunk in stream:
                    if chunk.choices:
                        content = chunk.choices[0].delta.content
                        if content:
                            yield content
            # ----------------------------------
            
            response = st.write_stream(parse_stream(stream))
            st.session_state.messages.append({"role": "assistant", "content": response})
        except Exception as e:
            st.error(f"Error: {e}")