import streamlit as st
from groq import Groq
import base64
import os
import pandas as pd
import PyPDF2
from dotenv import load_dotenv

# --- 1. SETUP ---
load_dotenv()
try:
    if "GROQ_API_KEY" in st.secrets:
        api_key = st.secrets["GROQ_API_KEY"]
    else:
        api_key = os.getenv("GROQ_API_KEY")
except:
    api_key = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="Gemini Pro Chat", page_icon="‚ú®", layout="wide")

# --- 2. CSS STYLING (‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå) ---
st.markdown("""
<style>
    /* ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≤‡∏ß‡∏™‡∏∞‡∏≠‡∏≤‡∏î */
    .stApp {
        background-color: #ffffff;
        color: #1f1f1f;
    }
    
    /* ‡∏ã‡πà‡∏≠‡∏ô Header/Footer */
    header {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* --- ‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå (Fixed Position) --- */
    /* ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏™‡πà width: fit-content ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏•‡πà‡∏≠‡∏á‡∏´‡∏ô‡πÑ‡∏õ‡∏ö‡∏±‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå */
    .stPopover {
        position: fixed;
        bottom: 80px;      /* ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå */
        right: 30px;       /* ‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏Ç‡∏ß‡∏≤ (‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á User ‡∏û‡∏¥‡∏°‡∏û‡πå) */
        z-index: 9999;
        width: fit-content !important; /* ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å‡∏Å‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ */
    }
    
    /* ‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏∏‡πà‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢ */
    .stPopover button {
        background-color: #f0f4f9 !important;
        color: #444746 !important;
        border: none !important;
        border-radius: 50% !important;
        width: 50px !important;
        height: 50px !important;
        font-size: 20px !important;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
    }
    .stPopover button:hover {
        background-color: #d3e3fd !important;
        color: #0b57d0 !important;
    }

    /* --- Chat Bubble --- */
    .stChatMessage {
        background-color: transparent;
        border: none;
    }
    /* User Message */
    div[data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #e3f2fd; 
        border-radius: 20px;
        padding: 1rem;
        margin-bottom: 10px;
        border-bottom-right-radius: 5px;
    }
    /* Bot Message */
    div[data-testid="stChatMessage"]:nth-child(even) {
        background-color: #ffffff;
        padding: 1rem;
    }
    
    /* ‡∏Ç‡∏¢‡∏±‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° */
    .stChatInputContainer {
        padding-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. HELPER FUNCTIONS ---
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

def extract_text_from_file(uploaded_file):
    try:
        if "pdf" in uploaded_file.type:
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            return "".join([page.extract_text() for page in pdf_reader.pages])
        elif "csv" in uploaded_file.type:
            return pd.read_csv(uploaded_file).to_markdown(index=False)
        elif "excel" in uploaded_file.type or "spreadsheet" in uploaded_file.type:
            return pd.read_excel(uploaded_file).to_markdown(index=False)
        else:
            return uploaded_file.getvalue().decode("utf-8")
    except Exception as e:
        return f"Error reading file: {str(e)}"

# --- 4. HEADER & SETTINGS ---
col1, col2 = st.columns([9, 1])
with col1:
    st.caption("‚ú® Gemini Pro Clone")
with col2:
    with st.popover("‚öôÔ∏è", help="‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"):
        mode = st.radio("Mode", ["Smart", "Creative", "Coder"])
        if st.button("üóëÔ∏è Reset Chat", type="primary", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

# --- 5. LOGIC & UI ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó
for msg in st.session_state.messages:
    if msg["role"] == "user":
        with st.chat_message("user", avatar="üë§"):
            content = msg["content"]
            if isinstance(content, list):
                for part in content:
                    if part["type"] == "text": st.markdown(part["text"])
                    if part["type"] == "image_url": st.image(part["image_url"]["url"], width=200)
            else:
                st.markdown(content)
    else:
        with st.chat_message("assistant", avatar="‚ú®"):
            st.markdown(msg["content"])

# --- ‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå (Floating Widget) ---
# ‡∏ß‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ‡πÅ‡∏ï‡πà CSS ‡∏à‡∏∞‡∏î‡∏µ‡∏î‡∏°‡∏±‡∏ô‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏Ç‡∏ß‡∏≤‡∏•‡πà‡∏≤‡∏á
with st.popover("üìé"):
    st.markdown("###### üìÇ ‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå")
    uploaded_file = st.file_uploader(
        "Upload", 
        type=["pdf", "csv", "xlsx", "txt", "jpg", "png"],
        label_visibility="collapsed"
    )
    
    file_content = ""
    is_image = False
    
    if uploaded_file:
        st.success(f"‚úÖ ‡πÅ‡∏ô‡∏ö: {uploaded_file.name}")
        if "image" in uploaded_file.type:
            is_image = True
            st.image(uploaded_file, width=150)
        else:
            file_content = extract_text_from_file(uploaded_file)

# --- CHAT INPUT ---
if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
    # 1. ‡πÅ‡∏™‡∏î‡∏á User Message
    st.chat_message("user", avatar="üë§").markdown(prompt)
    
    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    user_msg_obj = prompt
    model_to_use = "llama-3.3-70b-versatile"
    
    # Context prompt
    system_prompt = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà"
    if mode == "Creative": system_prompt = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏π‡πà‡∏Ñ‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á"
    if mode == "Coder": system_prompt = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç ‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î"

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏ö
    if uploaded_file:
        if is_image:
            model_to_use = "meta-llama/llama-4-scout-17b-16e-instruct"
            base64_img = encode_image(uploaded_file)
            user_msg_obj = [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
            ]
            st.session_state.messages.append({"role": "user", "content": user_msg_obj})
        else:
            system_prompt += f"\n\n[CONTEXT FROM FILE]:\n{file_content}\n\n[INSTRUCTION]: ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"
            st.session_state.messages.append({"role": "user", "content": prompt})
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})

    # 3. ‡∏™‡πà‡∏á API
    messages_payload = [{"role": "system", "content": system_prompt}]
    for m in st.session_state.messages[:-1]:
        c = m["content"]
        if isinstance(c, list):
            text_only = ""
            for p in c:
                if p["type"] == "text": text_only += p["text"]
            messages_payload.append({"role": m["role"], "content": text_only})
        else:
            messages_payload.append({"role": m["role"], "content": c})
    
    messages_payload.append({"role": "user", "content": user_msg_obj})

    # 4. ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡πÅ‡∏Å‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏î‡∏≤‡∏ß‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß)
    with st.chat_message("assistant", avatar="‚ú®"):
        try:
            client = Groq(api_key=api_key)
            stream = client.chat.completions.create(
                messages=messages_payload,
                model=model_to_use,
                temperature=0.7,
                stream=True,
            )
            
            # Generator ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡∏∞ Text ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å JSON stream
            def parse_stream(stream):
                for chunk in stream:
                    if chunk.choices:
                        content = chunk.choices[0].delta.content
                        if content:
                            yield content
            
            response = st.write_stream(parse_stream(stream))
            st.session_state.messages.append({"role": "assistant", "content": response})
        except Exception as e:
            st.error(f"Error: {e}")